{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np# Массивы (матрицы, векторы, линейная алгебра)\n",
    "import matplotlib.pyplot as plt # Научная графика\n",
    "%matplotlib inline\n",
    "    # Говорим jupyter'у, чтобы весь графический вывод был в браузере, а не в отдельном окне\n",
    "import pandas as pd             # Таблицы и временные ряды (dataframe, series)\n",
    "import seaborn as sns           # Еще больше красивой графики для визуализации данных\n",
    "import sklearn                  # Алгоритмы машинного обучения\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Описание задачи\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данными для задачи является набор объявлений о продаже `423857` поддержанных автомобилей на территории США. Данные собраны с портала Craigslist.org - самой большой в мире коллекции подержанных автомобилей \n",
    "\n",
    "\n",
    "##### Постановка задачи:\n",
    "С помощью методов машинного обучения, научить модель определять `condition` - состояние машины:\n",
    "\n",
    "| Состояние | Описание на русском | \n",
    "| ---- | ---- |\n",
    "| 'excellent' | превосходное, уникальное |\n",
    "| 'new' | новое, но без изысков |\n",
    "| 'like new' | с пробегом, но работает как новая |\n",
    "| 'good' | хорошее |\n",
    "| 'fair' | удовлетворительное |\n",
    "| 'salvage' | неудовлетворительное |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Чтение и разбор данных\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File vehicles.csv does not exist: 'vehicles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-009458c5f08c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"vehicles.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfull_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Читаем данные\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File vehicles.csv does not exist: 'vehicles.csv'"
     ]
    }
   ],
   "source": [
    "url = \"vehicles.csv\"\n",
    "full_data = pd.read_csv(url) # Читаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.shape # Получаем размерность данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обзор данных и их типов:\n",
    "1. `id` - уникальный номер объявления, `номинальный`\t\n",
    "2. `url` - ссылка на объявление о продаже, `номинальный`\t\n",
    "3. `region` - регион продажи автомобиля, `номинальный`\t\n",
    "4. `region_url` - ссылка на домен региона продажи, `номинальный`\t\n",
    "5. `price` - стоимость машины в долларах, `количественный`\t\n",
    "6. `year` - год выпуска машины, `номинальный`\t\n",
    "7. `manufacturer` - марка машины, `номинальный`\t\n",
    "8. `model` - модель машины, `номинальный`\t\n",
    "9. `condition` - состояние машины, `номинальный`\t\n",
    "10. `cylinders` - количество цилиндров в двигателе, `номинальный`\t\n",
    "11. `fuel` - тип двигателя, `номинальный`\t\n",
    "12. `odometer` - пробег, `количественный`\t\n",
    "13. `title_status` - официальный статус в государственном реестре \n",
    "(чистая, в залоге, угнана, только на запчасти, востановленная, металлолом), `номинальный`\n",
    "14. `transmission` - тип коробки передач, `номинальный`\t\n",
    "15. `vin` - уникальный идентификационный номер машины, `номинальный`\t\n",
    "16. `drive` - тип привода (передний, задний, 4x4), `номинальный`\t\n",
    "17. `size` - габариты машины, `номинальный`\t\n",
    "18. `type` - тип кузова, `номинальный`\t\n",
    "19. `paint_color` - цвет машины, `номинальный`\t\n",
    "20. `image_url` - сслыка на фотографию, `номинальный`\t\n",
    "21. `description` - мета-тег дескриптор страницы объявления, `номинальный`\n",
    "22. `county` - страна продажи автомобиля, `номинальный`\n",
    "23. `state` - штат продажи автомобиля, `номинальный`\t\n",
    "24. `lat` - широта, `количественный`\t\n",
    "25. `long` - долгота, `количественный`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обзор данных:\n",
    "\n",
    "С помощью метода `Dataframe.describe()` библиотеки `pandas`, осмотрим наши столбцы данных на наличе пустых столбов, аномалий или закономерностей\n",
    "###### Для номинальных признаков\n",
    "`count` - количество значений \n",
    "\n",
    "`unique` - количество уникальных значений в каждом столбце\n",
    "\n",
    "`top` - самое распространенное значение\n",
    "\n",
    "`freq` - частота наиболее распространенного значения\n",
    "\n",
    "###### Для количественных признаков:\n",
    "`mean` - Среднее арифметическое\n",
    "\n",
    "`std` - Стандартное отклонение\n",
    "\n",
    "`min` - Минимальное значение\n",
    "\n",
    "`25%` - Квартиль уровня (1/4)\n",
    "\n",
    "`50%` - Медиана\n",
    "\n",
    "`75%` - Квартиль уровня (3/4)\n",
    "\n",
    "`max` - Максимальное значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.iloc[:,:15].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.iloc[:,15:].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Благодаря такой проверке был обнаружен пустой столбец - `county`, который мы исключим из данных при дальнейшей работе\n",
    "\n",
    "\n",
    "* Самое встречаемое значение наших классов состояния машин - `excellent`, количество непропущенных строк даных - `176719`, а частота входжения - `85254`, что составляет - `48%` значений всего класса, а значит наши классы по этому столбцу - сбалансированны \n",
    "(при условии что баланс считаем нарушенным если, один класс занимает более 75% от класса)\n",
    "\n",
    "* Так же видно что данные содержат пропущенные значения в некоторых столбцах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Визуализация данных и описательная статистика\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим диаграмму по двум количественным признакам - цене от пробегу автомобиля, предполагаем что эти данные зависимы т.к с ростом пробега, будет уменьшатся цена автомобиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(full_data['odometer'], full_data['price']) \n",
    "plt.xlabel('odometer')\n",
    "plt.ylabel('price')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим большие выбросы, не дающие адекватно рассмотреть диаграмму рассеивания от наших двух признаков, попробуем рассмотреть диаграмму на рандомной выборке для 1000 объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(73)\n",
    "random_subset = np.random.choice(np.arange(full_data.shape[0]), size=1000, replace=False)\n",
    "\n",
    "plt.scatter(full_data.iloc[random_subset]['odometer'], full_data.iloc[random_subset]['price'], alpha=0.4)\n",
    "plt.xlabel('odometer')\n",
    "plt.ylabel('price')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что большие величины выбросов не дают возможность адекватно отрисовать диаграмму, а значит для дальнейшей работы над визуализацией нам нужно очистить данные от выбросов, и заодно избавиться от пустого столбца, обнаруженного на этапе чтения данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обнаружение и очистка от выбросов: \n",
    "Для обнаружения выбросов найдем, квантили для признаков `odometer` и `price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['price'].quantile([0.005,.01,.05,.080,.09,.1,.5,.9,.95,.99,.995])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['price'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим квартили уровней 0.005 - 0.080, которые говорят что около $7.5\\%$ машин - \"бесплатные\", эти данные нам нужноо отсечь\n",
    "\n",
    "Для работы возьмем интервал от 0.090 до 0.995 - это $90.5\\%$ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['odometer'].quantile([0.005,.01,.05,.1,.5,.9,.95,.99,.995])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['odometer'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично рассматриваем данные о пробеге автомобиля. В данном случае пробег у машины может быть нулевой если она новая, и такие данные уже будут адекватно вписываться в модель обучения. Их исключать мы не будем, и возьмем $99.0\\%$ данных, с пробегами в промежутках от `0км` до `330'000км`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новую переменную `clear_data` - куда занесем только очищенные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop = full_data[\n",
    "    (full_data['price'] < full_data['price'].quantile(0.090)) | (full_data['price'] > full_data['price'].quantile(0.995)) | \n",
    "    (full_data['odometer']  < full_data['odometer'].quantile(0.005)) | (full_data['odometer']  > full_data['odometer'].quantile(0.995))].index\n",
    "clear_data = full_data.drop(rows_to_drop)\n",
    "\n",
    "del clear_data['county']\n",
    "\n",
    "clear_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, как теперь будет выглядеть диаграмма, которую мы отрисовывали выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clear_data['odometer'], clear_data['price'], alpha = 0.01) \n",
    "plt.xlabel('odometer')\n",
    "plt.ylabel('price')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь диаграмма рассеивания выглядит адекватно, мы видим линейную зависимость уменьшения цены, при увеличении пробега автомобиля, но данных довольно много из-за чего сложно понять где большее или меньшее скопление точек, отрисуем более наглядный вариант диаграммы с меньшим числом объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(73)\n",
    "random_subset = np.random.choice(np.arange(clear_data.shape[0]), size=1000, replace=False)\n",
    "\n",
    "plt.scatter(clear_data.iloc[random_subset]['odometer'], clear_data.iloc[random_subset]['price'], alpha=0.4)\n",
    "plt.xlabel('odometer')\n",
    "plt.ylabel('price')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Визуализация данных\n",
    "\n",
    "Теперь, когда мы очистили данные, попробуем визуализировать зависимость признака по которому мы собираемся классифицировать данные, от различных других признаков\n",
    "За состояние автомобиля будет отвечать цвет, за год выпуска - размер, а так же оставим для осей ординат и абцисс - стоимость и пробег соотвественно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(73)\n",
    "random_subset = np.random.choice(np.arange(clear_data.shape[0]), size=1000, replace=False)\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.scatterplot(x='odometer', y='price', size='year', hue='condition', data=clear_data.iloc[random_subset], alpha=0.5)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Наблюдается ожидаемая корреляция между пробегом и стоимостью автомобия\n",
    "\n",
    "* Так же видим что машины состояния `fair` - удовлетворительно и `salvage` - неудовлетворительно, находятся по стоимости в районе менее `10'000$`, и наоборот самые дорогие машины, чаще всего в состоянии `excelent` и `like new`\n",
    "\n",
    "* Машин 1950г и ранее - на диаграмме почти нет\n",
    "\n",
    "* Почти все машины из класса `like new` - имеют пробег не более `150'000км` -  `200'000км`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим все возможные диаграммы рассеивания для каждой пары переменных, на небольшой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(73)\n",
    "random_subset = np.random.choice(np.arange(clear_data.shape[0]), size=10000, replace=False)\n",
    "sns.pairplot(clear_data.iloc[random_subset], hue='condition', diag_kind='hist')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из диаграмм видно, что есть зависимости:\n",
    "* цена/пробег\n",
    "* цена/год\n",
    "* пробег/год\n",
    "* ширина/долгота"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же можно посмотреть гистограммы для наших 3-х основных \n",
    "\n",
    "количественных признаков - стоимости, года и пробега"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(clear_data['price'], bins = 20)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(clear_data['odometer'], bins = 20)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(clear_data['year'], bins = 20)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Количественные признаки\n",
    "\n",
    "Для более полного анализа данных, построим кореляционную матрицу и оценим степень зависимости количественных признаков друг от друга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = clear_data.corr()\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_mat, square=True, cmap='seismic', annot = True, vmin=-1, vmax=1, center= 0)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat.where(np.triu(corr_mat > 0.2, k=1) | np.triu(corr_mat < -0.2, k=1)).stack().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корреляция наблюдается у 4-х пар признаков:\n",
    "\n",
    "| признак 1 | признак 2 | степень корреляции |\n",
    "| ----- | ---- | -------------- |\n",
    "| price | year |       0.305079 |\n",
    "| lat   | long |     -0.206862  |\n",
    "| year  | odometer |  -0.368601 |\n",
    "| price | odometer |  -0.511734 |\n",
    "\n",
    "Больше всего коррелируют цена и пробег, но значение корреляции все равно не очень большое, нужно так же проверить номинальные признаки, на возможные зависимости\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Номинальные признаки\n",
    "\n",
    "Рассмотрим балансы внутри классов данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['region'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['manufacturer'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['model'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['condition'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['cylinders'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['fuel'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['title_status'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['transmission'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['drive'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['paint_color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data['state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По частоте вхождений данных, можно назвать 3 класса - несбаласированными:\n",
    "* `transmission` - тип коробки передач\n",
    "\n",
    "| transmission  | 295445 | % |\n",
    "| ---- | ---- | --- |\n",
    "| automatic   | 263213 | 89 |\n",
    "| manual      |  21796 | 7 |\n",
    "| other       |  10436 | 4 |\n",
    "\n",
    "* `title_status` - официальный статус в государственном реестре \n",
    "\n",
    "| title_status  | 295043 | % |\n",
    "| ---- | ---- | --- |\n",
    "| clean |        283253 | 96 |\n",
    "| rebuilt |        5874 | 2 |\n",
    "| salvage |        3164 | 1 |\n",
    "| lien    |        1919 | 0,6 |\n",
    "| missing |         659 | 0,3 |\n",
    "| parts only |      174 | 0,1 |\n",
    "\n",
    "* `fuel` - тип двигателя\n",
    "\n",
    "| fuel  | 294428 | % |\n",
    "| ---- | ---- | --- |\n",
    "| gas         | 260888 | 88,6 |\n",
    "| diesel      | 20316  | 6,9 |\n",
    "| other       |  8902  | 3 |\n",
    "| hybrid      |  3427  | 1,1 |\n",
    "| electric    |   895  | 0,4 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же подробнее рассмотрим состояние машин, по котрому мы будем их классифицировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='condition', order=clear_data['condition'].value_counts().index, hue='transmission', data=clear_data)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что машины с коробками передач типа(вариатор или роботизированной) в большинстве случаев находятся в хорошем состоянии, значит это своеобразный индикатор, для более точного определения состояния машины, так же и тип двигателя имеет похожий вид гистограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='condition', order=clear_data['condition'].value_counts().index, hue='paint_color', data=clear_data)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а вот цвет машины почти ничего не может сказать о ее состоянии, похожая картина получается при рассмотрении состояния с признаками `type`, `size`, `drive`, `cylinders`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также посмотрим информацию о характере распределения состояния от цены/года и пробега автомобиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"condition\", y=\"price\", data=clear_data)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"condition\", y=\"year\", data=clear_data)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"condition\", y=\"odometer\", data=clear_data)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Обработка пропущенных значений\n",
    "***\n",
    "Посмотрим на число пропущенных значений в каждом столбце"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data.isna().sum()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем признаке состояния машины находится 217865 (57%) пропущенных значений, что ставит вопрос о том как правильно обработать эти значения? \n",
    "\n",
    "Первый вариант - просто удалить эти данные, оставив 43% данных для обучения модели\n",
    "\n",
    "Второй - заместить средним все показатели, кроме самого класса и так же удалить только те строки, значение класса в которых для нас не известно\n",
    "\n",
    "В любом случае статистическая мощность будет уменьшаться, и на данном этапе невозможно предсказать какой из методов покажет себя лучше, поэтому будем использовать 2 параллельных набора данных с 2-мя типами обработки пропущенных значений `delete_data` и `predict_data`, и посмотрим как в итоге это повлияет на ошибку при обучении модели\n",
    "\n",
    "Так же столбцы, `url`, `region_url`, `image_url`, `description`, `vin` не имеют особого смысла для модели, а так же их будет очень сложно бинаризовать для дальнейшего обучения, поэтому удалим их на этом этапе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### обработка номинальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "predict_data = copy.deepcopy(clear_data)\n",
    "predict_data.drop(['url','region_url','image_url','description','vin'], axis='columns', inplace=True)\n",
    "predict_data.fillna(predict_data.median(axis = 0), axis=0 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data.isna().sum()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### обработка категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data['manufacturer'].fillna(predict_data['manufacturer'].mode().iloc[0], inplace=True)\n",
    "predict_data['model'].fillna(predict_data['model'].mode().iloc[0], inplace=True)\n",
    "predict_data['cylinders'].fillna(predict_data['cylinders'].mode().iloc[0], inplace=True)\n",
    "predict_data['fuel'].fillna(predict_data['fuel'].mode().iloc[0], inplace=True)\n",
    "predict_data['title_status'].fillna(predict_data['title_status'].mode().iloc[0], inplace=True)\n",
    "predict_data['transmission'].fillna(predict_data['transmission'].mode().iloc[0], inplace=True)\n",
    "predict_data['drive'].fillna(predict_data['drive'].mode().iloc[0], inplace=True)\n",
    "predict_data['size'].fillna(predict_data['size'].mode().iloc[0], inplace=True)\n",
    "predict_data['type'].fillna(predict_data['type'].mode().iloc[0], inplace=True)\n",
    "predict_data['paint_color'].fillna(predict_data['paint_color'].mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data.isna().sum()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И последним шагом, оставляем в наших данных только те, значение класса для которых нам известно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Исключение пропущенных значений\n",
    "Соберем второй датасет, не используя принцип замены показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_data = copy.deepcopy(clear_data)\n",
    "delete_data.drop(['url','region_url','image_url','description','vin'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь удалим все встроки с вхождением пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Обработка категореальных признаков\n",
    "***\n",
    "Для алгоритмов нам потребуется провести бинаризацию данных для всех категориальных признаков, особое внимание нужно обратить на столбец - `model` и `region` содеращие большое количество уникальных признаков, и имеющие написание в формате предложения, а не одного слова. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_data['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cloud = set()\n",
    "\n",
    "for val in predict_data['model']:      \n",
    "    val = str(val)\n",
    "    tokens = val.split()\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower() \n",
    "        count_cloud.add(tokens[i])\n",
    "\n",
    "model_dummies = pd.DataFrame(count_cloud).T\n",
    "model_dummies.rename(columns=model_dummies.iloc[0], inplace=True)\n",
    "model_dummies.iloc[0] = 0\n",
    "\n",
    "\"\"\"\n",
    "import re\n",
    "def substr(word, words):\n",
    "    list=(re.findall(r\"[\\w']+\", words))\n",
    "    if word in list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for i in range(predict_data['model'].size):\n",
    "    for j in range(len(count_cloud)):\n",
    "        model_dummies.at[i,model_dummies.columns[j]] = substr(model_dummies.columns[j],predict_data['model'].iloc[i])\n",
    "\"\"\"\n",
    "\n",
    "model_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная функция собирает облако уникальных слов содержащихся в параметре, и создает для нее pandas dataframe с фиктивными dummy-признаками, но к сожалению выходная размерность облака слов - `6183`, а число строк `predict_data - 164421`, очень велики, из-за чего не удается бинаризировать признак `model`, а так же и признак `region` на размерностях - `497 * 57930`\n",
    "\n",
    "В данной работе, эти признаки так же придется убрать из рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_data.drop(['model','region'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data.drop(['model','region'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот с оставшимися категориальными признаками, проводим бинаризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(name, data):\n",
    "    return_data = data\n",
    "    return_data[name] = return_data[name].astype('category')\n",
    "    p_dummies = pd.get_dummies(return_data[name])   \n",
    "    return_data = pd.concat([return_data, p_dummies], axis=1)\n",
    "    return return_data\n",
    "\n",
    "predict_data = dummies('state', predict_data)    \n",
    "predict_data = dummies('manufacturer', predict_data)\n",
    "predict_data = dummies('cylinders', predict_data)\n",
    "predict_data = dummies('fuel', predict_data)\n",
    "predict_data = dummies('title_status', predict_data)\n",
    "predict_data = dummies('transmission', predict_data)\n",
    "predict_data = dummies('drive', predict_data)\n",
    "predict_data = dummies('size', predict_data)\n",
    "predict_data = dummies('type', predict_data)\n",
    "predict_data = dummies('paint_color', predict_data)\n",
    "\n",
    "predict_data.drop(['state','manufacturer','cylinders','fuel','title_status',\n",
    "                   'transmission','drive','size','type',\n",
    "                   'paint_color'], axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_data = dummies('state', delete_data)    \n",
    "delete_data = dummies('manufacturer', delete_data)\n",
    "delete_data = dummies('cylinders', delete_data)\n",
    "delete_data = dummies('fuel', delete_data)\n",
    "delete_data = dummies('title_status', delete_data)\n",
    "delete_data = dummies('transmission', delete_data)\n",
    "delete_data = dummies('drive', delete_data)\n",
    "delete_data = dummies('size', delete_data)\n",
    "delete_data = dummies('type', delete_data)\n",
    "delete_data = dummies('paint_color', delete_data)\n",
    "\n",
    "delete_data.drop(['state','manufacturer','cylinders','fuel','title_status',\n",
    "                   'transmission','drive','size','type',\n",
    "                   'paint_color'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Нормализация и деление на выборки\n",
    "***\n",
    "Так же нормализуем полученные данные, что бы большие величины, не внесли больше вклада в веса сети, чем следовало бы\n",
    "\n",
    "\n",
    "Для каждого набора данных возьем пропорциональное количество данных - \n",
    "\n",
    "75%/25% для обучения и тестовых, что бы точнее сравнить результат "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = predict_data['condition']\n",
    "y2 = delete_data['condition']\n",
    "\n",
    "predict_data.drop(['condition'], axis='columns', inplace=True)\n",
    "delete_data.drop(['condition'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = (predict_data - predict_data.mean(axis = 0))/predict_data.std(axis = 0)\n",
    "x2 = (delete_data - delete_data.mean(axis = 0))/delete_data.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.to_numpy()\n",
    "x2 = x2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y1.replace(['excellent','new','like new','good','fair','salvage'], [6, 5, 4, 3, 2, 1])\n",
    "y2 = y2.replace(['excellent','new','like new','good','fair','salvage'], [6, 5, 4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y1.to_numpy()\n",
    "y2 = y2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные на обучающие выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(x1, y1, test_size = 0.25, random_state = 73)\n",
    "\n",
    "N1_train, _ = X1_train.shape \n",
    "N1_test,  _ = X1_test.shape \n",
    "\n",
    "N1_train, N1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(x2, y2, test_size = 0.25, random_state = 73)\n",
    "\n",
    "N2_train, _ = X2_train.shape \n",
    "N2_test,  _ = X2_test.shape \n",
    "\n",
    "N2_train, N2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Классификатор ближайших соседей\n",
    "\n",
    "Запустим классифифкатор ближайших N соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors = 10)\n",
    "#knn.set_params(n_neighbors=10)\n",
    "knn1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test_predict = knn1.predict(X1_test)\n",
    "err_test1  = np.mean(y1_test  != y1_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ошибки и выводы\n",
    "\n",
    "Для к "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = stand_predict_data['Price']\n",
    "X1 = stand_predict_data.drop(['Date'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
